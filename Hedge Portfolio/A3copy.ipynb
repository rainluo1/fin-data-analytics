{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data from external file:\n",
    "monthly_data = pd.read_sas(\"./CA.sas7bdat\")\n",
    "return_data = pd.read_sas(\"./returndata.sas7bdat\")\n",
    "ff_data = pd.read_sas(\"./factors_monthly.sas7bdat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date   mktrf     smb     hml      rf    year  month  umd     dateff\n",
      "0 1926-07-01  0.0296 -0.0256 -0.0243  0.0022  1926.0    7.0  NaN 1926-07-31\n",
      "1 1926-08-01  0.0264 -0.0117  0.0382  0.0025  1926.0    8.0  NaN 1926-08-31\n",
      "2 1926-09-01  0.0036 -0.0140  0.0013  0.0023  1926.0    9.0  NaN 1926-09-30\n",
      "3 1926-10-01 -0.0324 -0.0009  0.0070  0.0032  1926.0   10.0  NaN 1926-10-30\n",
      "4 1926-11-01  0.0253 -0.0010 -0.0051  0.0031  1926.0   11.0  NaN 1926-11-30\n"
     ]
    }
   ],
   "source": [
    "#print (monthly_data.head())\n",
    "print(ff_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PERMNO', 'DATE', 'RET', 'monthid'], dtype='object')\n",
      "Index(['PERMNO', 'date_x', 'yyyymm', 'ret', 'ret_t1', 'lnsize', 'bk2mkt', 'ep',\n",
      "       'beta', 'ivol', 'CUSIP', 'COMNAM', 'TICKER', 'PRC', 'SHROUT', 'monthid',\n",
      "       'me', 'gvkey', 'DATADATE', 'ATQ', 'CEQQ', 'EPSPXQ', 'IBQ', 'SALEQ',\n",
      "       'DATE', 'RET', 'date_y', 'mktrf', 'smb', 'hml', 'rf', 'year', 'month',\n",
      "       'umd', 'dateff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#merge based on PERMNO\n",
    "monthly_data[\"monthid\"] = (monthly_data.date.dt.year-2000)*12 + monthly_data.date.dt.month\n",
    "ff_data[\"monthid\"] = (ff_data.date.dt.year-2000)*12 + ff_data.date.dt.month\n",
    "return_data[\"monthid\"] = (return_data.DATE.dt.year-2000)*12 + return_data.DATE.dt.month\n",
    "ff_data = ff_data[(ff_data['monthid']>=1) & (ff_data['monthid']<=299) ]\n",
    "monthly_data = monthly_data.rename(columns={'permno': 'PERMNO'})\n",
    "print(return_data.columns)\n",
    "mergedf = pd.merge(monthly_data,return_data,how=\"left\", on=[\"PERMNO\",\"monthid\"])\n",
    "merged = pd.merge(mergedf, ff_data,how=\"left\",on=[\"monthid\"])\n",
    "print(merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration: Online resources were used to ensure clearity of this.\n",
    "# Credit: ChatGPT: asked for a cleaner version of groupby(\"PERNMO\")\n",
    "\n",
    "def compound_return(returns):\n",
    "    # returns: a numpy array of returns\n",
    "    return (1 + returns).prod() - 1\n",
    "\n",
    "merged['MOM'] = (\n",
    "    merged.groupby(\"PERMNO\")[\"ret\"]\n",
    "      .apply(lambda x: x.rolling(window=12, min_periods=10)\n",
    "                   .apply(compound_return, raw=True))\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_series(s, lower=0.01, upper=0.99):\n",
    "    return s.clip(lower=s.quantile(lower), upper=s.quantile(upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043885755117170834\n",
      "1.6281686076534982\n",
      "0.2906433282955342\n",
      "0.018272399983715378\n",
      "0.7365577842493983\n",
      "0.010575730630191871\n",
      "\n",
      "0.7876318612427587\n",
      "1.6751919220228833\n",
      "0.37727926332245254\n",
      "0.043885755117170834\n",
      "0.7999771455954879\n",
      "0.011511088926617672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "merged['MOM_winsorize'] = winsorize_series(merged['MOM'])\n",
    "merged['bk2mkt_winsorize'] = winsorize_series(merged['bk2mkt'])\n",
    "merged['lnsize_winsorize'] = winsorize_series(merged['lnsize'])\n",
    "merged['ep_winsorize'] = winsorize_series(merged['ep'])\n",
    "merged['beta_winsorize'] = winsorize_series(merged['beta'])\n",
    "merged['ivol_winsorize'] = winsorize_series(merged['ivol'])\n",
    "\n",
    "print(merged['ep'].std())\n",
    "print(merged['lnsize_winsorize'].std())\n",
    "print(merged['bk2mkt_winsorize'].std())\n",
    "print(merged['ep_winsorize'].std())\n",
    "print(merged['beta_winsorize'].std())\n",
    "print(merged['ivol_winsorize'].std())\n",
    "print(\"\")\n",
    "print(merged['MOM'].std())\n",
    "print(merged['lnsize'].std())\n",
    "print(merged['bk2mkt'].std())\n",
    "print(merged['ep'].std())\n",
    "print(merged['beta'].std())\n",
    "print(merged['ivol'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistic(array):\n",
    "    print(\"number of observation\",len(array))\n",
    "    print(\"mean:\",np.mean(array))\n",
    "    print(\"std: \",np.std(array))\n",
    "    print(\"min:\",np.min(array))\n",
    "    print(\"max:\",np.max(array))\n",
    "    print(\"1st percentile\", np.percentile(array,1))\n",
    "    print(\"99st percentile\", np.percentile(array,99))\n",
    "    print(\"Maximum\", np.max(array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observation 21863\n",
      "mean: 0.2442010116841693\n",
      "std:  0.7876138481414522\n",
      "min: -0.9722955122681691\n",
      "max: 53.662785856291336\n",
      "1st percentile -0.6399789813149054\n",
      "99st percentile 2.2192849928771516\n",
      "Maximum 53.662785856291336\n"
     ]
    }
   ],
   "source": [
    "summary_statistic(merged['MOM'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_factor_quintile(merged, factor):\n",
    "    # Define column names based on the factor.\n",
    "    winsor_col = f\"{factor}_winsorize\"      # e.g., \"ep_winsorize\"\n",
    "    \n",
    "    # Create the winsorized quintile variable by grouping by DATE.\n",
    "    merged[f\"{factor}_rank\"] = merged.groupby(\"monthid\")[winsor_col].transform(\n",
    "        lambda x: pd.qcut(x, q=5, labels=False, duplicates=\"drop\") + 1\n",
    "    )\n",
    "    merged.sort_values([\"monthid\", f\"{factor}_rank\"], inplace=True)\n",
    "    \n",
    "    # Group by the monthid.\n",
    "    merged[f\"monthid_{factor}\"] = merged[\"monthid\"].astype(str) + merged[f\"{factor}_rank\"].astype(str)\n",
    "    groups = merged.groupby([f\"monthid_{factor}\"])\n",
    "    \n",
    "    # Initialize dictionary to accumulate quintile summary statistics.\n",
    "    quintile = {\n",
    "        \"monthid\": [],\n",
    "        f\"{factor}_rank\": [],\n",
    "        \"ret_t1\": [],\n",
    "        factor:[]\n",
    "    }\n",
    "    \n",
    "    # Loop over each group (each unique month/quintile combination).\n",
    "    for name, group in groups:\n",
    "        quintile[\"monthid\"].append(group[\"monthid\"].iloc[0])\n",
    "        # Using the computed rank directly:\n",
    "        quintile[f\"{factor}_rank\"].append(group[f\"{factor}_rank\"].iloc[0])\n",
    "        quintile[\"ret_t1\"].append(group['ret_t1'].mean())\n",
    "        quintile[factor].append(group[factor].mean())\n",
    "    \n",
    "    # Create a DataFrame from the aggregated statistics and sort.\n",
    "    quintile_df = pd.DataFrame(quintile)\n",
    "    quintile_df.sort_values([\"monthid\", f\"{factor}_rank\"], inplace=True)\n",
    "    quintile_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return quintile_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PERMNO', 'date_x', 'yyyymm', 'ret', 'ret_t1', 'lnsize', 'bk2mkt', 'ep',\n",
      "       'beta', 'ivol', 'CUSIP', 'COMNAM', 'TICKER', 'PRC', 'SHROUT', 'monthid',\n",
      "       'me', 'gvkey', 'DATADATE', 'ATQ', 'CEQQ', 'EPSPXQ', 'IBQ', 'SALEQ',\n",
      "       'DATE', 'RET', 'date_y', 'mktrf', 'smb', 'hml', 'rf', 'year', 'month',\n",
      "       'umd', 'dateff', 'MOM', 'MOM_winsorize', 'bk2mkt_winsorize',\n",
      "       'lnsize_winsorize', 'ep_winsorize', 'beta_winsorize', 'ivol_winsorize'],\n",
      "      dtype='object')\n",
      "   monthid  ep_rank    ret_t1        ep\n",
      "0        1      1.0  0.503356 -0.011105\n",
      "1        1      2.0  0.218565  0.003041\n",
      "2        1      3.0  0.271324  0.005944\n",
      "3        1      4.0  0.149769  0.011681\n",
      "4        1      5.0 -0.010883  0.049185\n",
      "   monthid  lnsize_rank    ret_t1     lnsize\n",
      "0        1          1.0  0.519571   5.846272\n",
      "1        1          2.0  0.196213   7.706301\n",
      "2        1          3.0  0.087781   8.660386\n",
      "3        1          4.0  0.150513   9.441580\n",
      "4        1          5.0  0.114786  11.356380\n",
      "   monthid  bk2mkt_rank    ret_t1    bk2mkt\n",
      "0        1          1.0  0.150673  0.041049\n",
      "1        1          2.0  0.301787  0.111470\n",
      "2        1          3.0  0.194455  0.165151\n",
      "3        1          4.0  0.463894  0.276947\n",
      "4        1          5.0  0.077927  0.631337\n",
      "   monthid  MOM_rank    ret_t1  MOM\n",
      "0        1       NaN  0.219233  NaN\n",
      "1        2       NaN  0.059248  NaN\n",
      "2        3       NaN -0.056810  NaN\n",
      "3        4       NaN -0.039814  NaN\n",
      "4        5       NaN  0.059284  NaN\n",
      "   monthid  beta_rank    ret_t1      beta\n",
      "0        1        1.0 -0.060394  0.473067\n",
      "1        1        2.0  0.053447  1.012389\n",
      "2        1        3.0  0.277906  1.340843\n",
      "3        1        4.0  0.576145  1.657404\n",
      "4        1        5.0  0.272226  2.500450\n",
      "   monthid  ivol_rank    ret_t1      ivol\n",
      "0        1        1.0  0.015135  0.018416\n",
      "1        1        2.0  0.113431  0.027399\n",
      "2        1        3.0  0.288768  0.036725\n",
      "3        1        4.0  0.166570  0.043864\n",
      "4        1        5.0  0.530817  0.057428\n"
     ]
    }
   ],
   "source": [
    "factors = ['ep','lnsize','bk2mkt','MOM','beta','ivol']\n",
    "quintile_port = []\n",
    "\n",
    "print(merged.columns)\n",
    "for f in factors:\n",
    "    df = compute_factor_quintile(merged,f)\n",
    "    quintile_port.append(df)\n",
    "    # add to excel\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PERMNO', 'date_x', 'yyyymm', 'ret', 'ret_t1', 'lnsize', 'bk2mkt', 'ep',\n",
       "       'beta', 'ivol', 'CUSIP', 'COMNAM', 'TICKER', 'PRC', 'SHROUT', 'monthid',\n",
       "       'me', 'gvkey', 'DATADATE', 'ATQ', 'CEQQ', 'EPSPXQ', 'IBQ', 'SALEQ',\n",
       "       'DATE', 'RET', 'date_y', 'mktrf', 'smb', 'hml', 'rf', 'year', 'month',\n",
       "       'umd', 'dateff', 'MOM', 'MOM_winsorize', 'bk2mkt_winsorize',\n",
       "       'lnsize_winsorize', 'ep_winsorize', 'beta_winsorize', 'ivol_winsorize',\n",
       "       'ep_rank', 'monthid_ep', 'lnsize_rank', 'monthid_lnsize', 'bk2mkt_rank',\n",
       "       'monthid_bk2mkt', 'MOM_rank', 'monthid_MOM', 'beta_rank',\n",
       "       'monthid_beta', 'ivol_rank', 'monthid_ivol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hedge_creation(quintlile,factor, long,short):\n",
    "    long_leg = quintlile.loc[quintlile[f\"{factor}_rank\"] == long]\n",
    "    short_leg = quintlile.loc[quintlile[f\"{factor}_rank\"] == short]\n",
    "    \n",
    "    hedge_port1 = pd.merge(long_leg,short_leg,on=['monthid'])\n",
    "    hedge_port1['hedge_ret'] = hedge_port1['ret_t1_x'] - hedge_port1['ret_t1_y']\n",
    "    #print(f\"long leg for {factor}:\",len(long_leg))\n",
    "    #print(len(short_leg))\n",
    "    hedge_port1 = pd.merge(hedge_port1,ff_data,on=['monthid'])\n",
    "    return hedge_port1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PERMNO', 'date_x', 'yyyymm', 'ret', 'ret_t1', 'lnsize', 'bk2mkt', 'ep',\n",
       "       'beta', 'ivol', 'CUSIP', 'COMNAM', 'TICKER', 'PRC', 'SHROUT', 'monthid',\n",
       "       'me', 'gvkey', 'DATADATE', 'ATQ', 'CEQQ', 'EPSPXQ', 'IBQ', 'SALEQ',\n",
       "       'DATE', 'RET', 'date_y', 'mktrf', 'smb', 'hml', 'rf', 'year', 'month',\n",
       "       'umd', 'dateff', 'MOM', 'MOM_winsorize', 'bk2mkt_winsorize',\n",
       "       'lnsize_winsorize', 'ep_winsorize', 'beta_winsorize', 'ivol_winsorize',\n",
       "       'ep_rank', 'monthid_ep', 'lnsize_rank', 'monthid_lnsize', 'bk2mkt_rank',\n",
       "       'monthid_bk2mkt', 'MOM_rank', 'monthid_MOM', 'beta_rank',\n",
       "       'monthid_beta', 'ivol_rank', 'monthid_ivol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthid</th>\n",
       "      <th>ivol_rank</th>\n",
       "      <th>ret_t1</th>\n",
       "      <th>ivol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.530817</td>\n",
       "      <td>0.057428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>0.069087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.087577</td>\n",
       "      <td>0.078528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.106266</td>\n",
       "      <td>0.062836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.204035</td>\n",
       "      <td>0.053835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>295</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.030773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.086352</td>\n",
       "      <td>0.033971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>297</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.027782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>298</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.126239</td>\n",
       "      <td>0.026609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>299</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.050875</td>\n",
       "      <td>0.039787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      monthid  ivol_rank    ret_t1      ivol\n",
       "4           1        5.0  0.530817  0.057428\n",
       "9           2        5.0 -0.010420  0.069087\n",
       "14          3        5.0 -0.087577  0.078528\n",
       "19          4        5.0 -0.106266  0.062836\n",
       "25          5        5.0  0.204035  0.053835\n",
       "...       ...        ...       ...       ...\n",
       "1526      295        5.0  0.015626  0.030773\n",
       "1531      296        5.0  0.086352  0.033971\n",
       "1536      297        5.0  0.007661  0.027782\n",
       "1541      298        5.0  0.126239  0.026609\n",
       "1546      299        5.0 -0.050875  0.039787\n",
       "\n",
       "[299 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quintile_port[5][quintile_port[5].ivol_rank == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:44: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:44: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:44: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:44: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:44: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:44: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
      "C:\\Users\\ruixu\\AppData\\Local\\Temp\\ipykernel_12148\\441793531.py:45: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  merged.to_excel(writer,\"part 1-2 data.xlsx\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0038756284104023383, 0.02300807381642754, -0.004400540860210706, -0.0013907993889061845, -0.011771832003055854, 0.01633453079082345]\n",
      "[0.8580197392159133, 6.712654230008553, -1.2232483480121823, -0.30485690852142666, -2.3307031651731434, 3.4299300617061106]\n",
      "[0.0050441655003027035, 0.023654581179785007, -0.00494934377919773, -0.0012282854587957357, -0.01171736729589615, 0.01631342658918957]\n",
      "[1.118978361864334, 6.8467754204640086, -1.3732781573245072, -0.26650105830643583, -2.2957628286053473, 3.3897493876775804]\n",
      "[0.06163517019603266, 0.40162959450179075, -0.07785476954266547, -0.01116197643480072, -0.13375157027728113, 0.19746031242767245]\n"
     ]
    }
   ],
   "source": [
    "factors = ['ep','lnsize','bk2mkt','MOM','beta','ivol']\n",
    "hedge_port = []\n",
    "hedge_port.append(hedge_creation(quintile_port[0],'ep',1,5))\n",
    "hedge_port.append(hedge_creation(quintile_port[1],'lnsize',1,5))\n",
    "hedge_port.append(hedge_creation(quintile_port[2],'bk2mkt',5,1))\n",
    "hedge_port.append(hedge_creation(quintile_port[3],'MOM',5,1))\n",
    "hedge_port.append(hedge_creation(quintile_port[4],'beta',1,5))\n",
    "hedge_port.append(hedge_creation(quintile_port[5],'ivol',5,1))\n",
    "\n",
    "alphas =[]\n",
    "alpha_t_stats =[]\n",
    "sharpe_list = []\n",
    "\n",
    "alphas_ff4 =[]\n",
    "alphas_ff4_t_stats =[]\n",
    "with pd.ExcelWriter('dataOutput.xlsx') as writer:\n",
    "    for i in range (0,6):\n",
    "\n",
    "        X = hedge_port[i][\"mktrf\"].values.reshape(-1, 1)\n",
    "        y = hedge_port[i][\"hedge_ret\"].values - hedge_port[i].rf\n",
    "        X_const = sm.add_constant(X)\n",
    "    # Fit the OLS model\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "    # Extract the intercept and its t-statistic\n",
    "        intercept = model.params[\"const\"]\n",
    "        t_stat_intercept = model.tvalues[\"const\"]\n",
    "        alphas.append(intercept)\n",
    "        alpha_t_stats.append(t_stat_intercept)\n",
    "\n",
    "        # for FF 4 model:\n",
    "        ff3explanatory = sm.add_constant(hedge_port[i][[\"mktrf\", \"smb\", \"hml\",'umd']])\n",
    "        ff3explanatory.reset_index(drop=True, inplace=True)\n",
    "    # compute sharpe ratio\n",
    "        sharpe = (hedge_port[i][\"hedge_ret\"].values - hedge_port[i].rf).mean()/hedge_port[i][\"hedge_ret\"].std()\n",
    "        sharpe_list.append(sharpe)\n",
    "\n",
    "    # run the linear models again\n",
    "        ff3_model = sm.OLS(y, ff3explanatory).fit()\n",
    "        intercept = ff3_model.params[\"const\"]\n",
    "        t_stat_intercept = ff3_model.tvalues[\"const\"]\n",
    "        alphas_ff4.append(intercept)\n",
    "        alphas_ff4_t_stats.append(t_stat_intercept)\n",
    "        #impor to excel\n",
    "        hedge_port[i].to_excel(writer,f\"{factors[i]} hedge portfolio.xlsx\")\n",
    "    merged.to_excel(writer,\"part 1-2 data.xlsx\")\n",
    "print(alphas)\n",
    "print(alpha_t_stats)\n",
    "\n",
    "print(alphas_ff4)\n",
    "print(alphas_ff4_t_stats)\n",
    "print(sharpe_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: unable to shortcell: only long leg: on high ivol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023164314231244994"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(high_ivol_merged[\"ret_t1\"].values - high_ivol_merged.rf - high_ivol_merged[\"mktrf\"].values).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029365927071666683\n",
      "4.980763870455956\n",
      "0.029767288144434224\n",
      "5.002931730549504\n"
     ]
    }
   ],
   "source": [
    "#hedge port 5 contains ivol port:\n",
    "\n",
    "high_ivol = quintile_port[5][quintile_port[5].ivol_rank == 5]\n",
    "high_ivol_merged = pd.merge(high_ivol,ff_data,on=['monthid'])\n",
    "\n",
    "X = high_ivol_merged[\"mktrf\"].values.reshape(-1, 1)\n",
    "y = high_ivol_merged[\"ret_t1\"].values - high_ivol_merged.rf\n",
    "X_const = sm.add_constant(X)\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X_const).fit()\n",
    "# Extract the intercept and its t-statistic\n",
    "alpha = model.params[\"const\"]\n",
    "t_stat_alpha = model.tvalues[\"const\"]\n",
    "\n",
    "\n",
    "# for FF 4 model:\n",
    "ff3explanatory = sm.add_constant(high_ivol_merged[[\"mktrf\", \"smb\", \"hml\",'umd']])\n",
    "ff3explanatory.reset_index(drop=True, inplace=True)\n",
    "# dependent is excess return at 2019 dec\n",
    "\n",
    "# run the linear models again\n",
    "ff3_model = sm.OLS(y, ff3explanatory).fit()\n",
    "ff_alpha = ff3_model.params[\"const\"]\n",
    "t_stat_ff_alpha = ff3_model.tvalues[\"const\"]\n",
    "\n",
    "\n",
    "print(alpha)\n",
    "print(t_stat_alpha)\n",
    "print(ff_alpha)\n",
    "print(t_stat_ff_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['monthid', 'ivol_rank', 'ret_t1', 'ivol'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# compute annual turnover\n",
    "print(high_ivol.columns)\n",
    "turn_over = 0\n",
    "\n",
    "#for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"ivol_rank\"] = merged.groupby(\"monthid\")[\"ivol_winsorize\"].transform(\n",
    "    lambda x: pd.qcut(x, q=5, labels=False, duplicates=\"drop\") + 1)\n",
    "\n",
    "# Step 2: Filter to keep only the top rank (5)\n",
    "group = merged[merged[\"ivol_rank\"] == 5]\n",
    "\n",
    "# Step 3: Group by month (yyyymm) - ensure the months are in sorted order\n",
    "group_date = group.groupby(\"yyyymm\")\n",
    "\n",
    "# Create a dictionary to store turnover values.\n",
    "# Turnover here is defined as the number of PERMNO that differ from the previous month.\n",
    "turnover_dict = {}\n",
    "prev_keys = None\n",
    "\n",
    "# Sorting the groups by the month key (assuming yyyymm is sortable)\n",
    "for month, data in sorted(group_date, key=lambda x: x[0]):\n",
    "    # Get the set of PERMNO keys for the current month.\n",
    "    curr_keys = set(data['PERMNO'].unique())\n",
    "    \n",
    "    # If this is not the first month, compute the symmetric difference.\n",
    "    if prev_keys is not None:\n",
    "        # Symmetric difference: keys in prev_keys or curr_keys but not in both.\n",
    "        diff = curr_keys - prev_keys\n",
    "        turnover_dict[month] = len(diff)\n",
    "    else:\n",
    "        # First month: no previous month to compare, so turnover can be set to None or 0.\n",
    "        turnover_dict[month] = None\n",
    "        \n",
    "    # Update prev_keys for the next iteration.\n",
    "    prev_keys = curr_keys\n",
    "\n",
    "# Optionally, you can compute overall summary statistics (e.g., average turnover excluding the first month).\n",
    "turnover_values = [v for v in turnover_dict.values() if v is not None]\n",
    "average_turnover = sum(turnover_values) / len(turnover_values) if turnover_values else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.953020134228188\n",
      "0.4185800070646415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(average_turnover)\n",
    "print(average_turnover/19)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.43624161073825"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_turnover*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 Fama Macbeth cross sectional asset pricing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ivol_merged_5 = pd.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beta    297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group[[\"beta\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 ret_t1   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.008\n",
      "Method:                 Least Squares   F-statistic:                     9.483\n",
      "Date:                Tue, 18 Mar 2025   Prob (F-statistic):           1.25e-07\n",
      "Time:                        18:31:21   Log-Likelihood:                 1443.4\n",
      "No. Observations:                4275   AIC:                            -2877.\n",
      "Df Residuals:                    4270   BIC:                            -2845.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1159      0.018      6.367      0.000       0.080       0.152\n",
      "ivol           0.0254      0.189      0.135      0.893      -0.344       0.395\n",
      "beta          -0.0025      0.003     -0.984      0.325      -0.007       0.002\n",
      "lnsize        -0.0088      0.002     -5.609      0.000      -0.012      -0.006\n",
      "bk2mkt        -0.0119      0.007     -1.740      0.082      -0.025       0.002\n",
      "==============================================================================\n",
      "Omnibus:                     3274.055   Durbin-Watson:                   1.503\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           379688.785\n",
      "Skew:                           2.897   Prob(JB):                         0.00\n",
      "Kurtosis:                      48.804   Cond. No.                         679.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "clean_group = group.dropna(subset=['beta', \"lnsize\", \"bk2mkt\", \"ivol\"])\n",
    "\n",
    "ff3explanatory = sm.add_constant(clean_group[[\"ivol\", \"beta\", \"lnsize\", \"bk2mkt\"]]).reset_index(drop=True)\n",
    "dependent = clean_group[\"ret_t1\"].reset_index(drop=True)\n",
    "\n",
    "ff3_model = sm.OLS(dependent, ff3explanatory).fit()\n",
    "print(ff3_model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
